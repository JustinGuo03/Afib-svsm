{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44e84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import wfdb\n",
    "import copy as cp\n",
    "import scipy.signal as signal\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef5d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_list = [] # Initialize the array that will hold the list of our records\n",
    "\n",
    "records = 'mit-bih-dataframes/subject_list.csv' # Get our record list like we did in the initial extraction\n",
    "with open(records) as rfile:# Load our records into the array\n",
    "    for record in rfile:\n",
    "        record = record[0:-1] # The -1 removes the newline (\"\\n\") character from the string\n",
    "        record_list.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ba557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdic = {}\n",
    "for idx, x in enumerate(record_list):\n",
    "    dfdic[x] = pd.read_csv('mit-bih-features/'+x+ '.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19fe91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df = pd.DataFrame()\n",
    "for idx, x in enumerate(record_list):\n",
    "    subject_df = pd.concat([subject_df, dfdic[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e542d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df['Mappedrhythmlabels'] = subject_df['rhythmLabel'].map({'Normal':0, 'Other':0, 'AFIB':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ec0cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "statcoefvar_dic = {\n",
    "    'Run Time': [],\n",
    "    'Accuracy': [],\n",
    "    'Standard Error': [],\n",
    "    'Sensitivity': [],\n",
    "    'Specificity': [],\n",
    "    'Precision': [],\n",
    "    'F1-Score': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42fd2d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Run time is 0.17195641500001102 seconds ---\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.8722847018949315, 0.8731895223420647, 0.8770416024653312, 0.875808936825886, 0.8805855161787365]\n",
      "Avg accuracy: 0.8757820559413899\n",
      "Std of accuracy : \n",
      "0.0029534090834018576\n",
      "\n",
      "[[17142  2284]\n",
      " [ 1747 11278]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89     19426\n",
      "           1       0.83      0.87      0.85     13025\n",
      "\n",
      "    accuracy                           0.88     32451\n",
      "   macro avg       0.87      0.87      0.87     32451\n",
      "weighted avg       0.88      0.88      0.88     32451\n",
      "\n",
      "0.882425615154947\n",
      "0.865873320537428\n",
      "0.907512308751125\n",
      "0.8947931619470182\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "acc_score = []\n",
    "Truth = []\n",
    "Output = []\n",
    "\n",
    "for train_index, test_index in kf.split(subject_df): \n",
    "    #X_train = subject_df.loc[train_index, [\"StoS\", \"StoR\", \"StoL\", \"RtoS\", \"RtoR\", \"RtoL\",\"LtoS\", \"LtoR\", \"LtoL\"]]\n",
    "    #X_test = subject_df.loc[test_index, [\"StoS\", \"StoR\", \"StoL\", \"RtoS\", \"RtoR\", \"RtoL\",\"LtoS\", \"LtoR\", \"LtoL\"]]\n",
    "    #Y_train = subject_df.loc[train_index, \"rhythmLabel\"]\n",
    "    #Y_test = subject_df.loc[test_index, \"rhythmLabel\"]\n",
    "    \n",
    "    X_train = subject_df.iloc[train_index, 13].values.reshape(-1,1)\n",
    "    X_test = subject_df.iloc[test_index, 13].values.reshape(-1,1)\n",
    "    Y_train = subject_df.iloc[train_index, -1]\n",
    "    Y_test = subject_df.iloc[test_index, -1]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(Y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "    Truth.extend(Y_test.values.reshape(Y_test.shape[0])) \n",
    "    Output.extend(pred_values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "\n",
    "print(\"---Run time is %s seconds ---\" % elapsed)\n",
    "print()\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print(\"Avg accuracy: {}\".format(np.mean(acc_score)))\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print()\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print()\n",
    "print(classification_report(Truth, Output))\n",
    "\n",
    "cm = confusion_matrix(Truth, Output)\n",
    "\n",
    "sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "f1_score = (2*precision*sensitivity)/(precision+sensitivity)\n",
    "\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(precision)\n",
    "print(f1_score)\n",
    "\n",
    "statcoefvar_dic['Run Time'].append(elapsed)\n",
    "statcoefvar_dic['Accuracy'].append(np.mean(acc_score))\n",
    "statcoefvar_dic['Standard Error'].append(np.std(acc_score))\n",
    "statcoefvar_dic['Sensitivity'].append(sensitivity)\n",
    "statcoefvar_dic['Specificity'].append(specificity)\n",
    "statcoefvar_dic['Precision'].append(precision)\n",
    "statcoefvar_dic['F1-Score'].append(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98eeee0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Run time is 9.467506043 seconds ---\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.8745955938992451, 0.8738058551617873, 0.8778120184899846, 0.8767334360554699, 0.8853620955315871]\n",
      "Avg accuracy: 0.8776617998276148\n",
      "Std of accuracy : \n",
      "0.004109717920482175\n",
      "\n",
      "[[16997  2429]\n",
      " [ 1541 11484]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90     19426\n",
      "           1       0.83      0.88      0.85     13025\n",
      "\n",
      "    accuracy                           0.88     32451\n",
      "   macro avg       0.87      0.88      0.87     32451\n",
      "weighted avg       0.88      0.88      0.88     32451\n",
      "\n",
      "0.8749613919489344\n",
      "0.8816890595009597\n",
      "0.9168734491315137\n",
      "0.8954272468654515\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "kf = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "model=LinearDiscriminantAnalysis()\n",
    "\n",
    "acc_score = []\n",
    "Truth = []\n",
    "Output = []\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(subject_df):\n",
    "  \n",
    "    X_train = subject_df.iloc[train_index, 13].values.reshape(-1,1)\n",
    "    X_test = subject_df.iloc[test_index, 13].values.reshape(-1,1)\n",
    "    Y_train = subject_df.iloc[train_index, -1]\n",
    "    Y_test = subject_df.iloc[test_index, -1]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(Y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "    Truth.extend(Y_test.values.reshape(Y_test.shape[0])) \n",
    "    Output.extend(pred_values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "\n",
    "print(\"---Run time is %s seconds ---\" % elapsed)\n",
    "print()\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print(\"Avg accuracy: {}\".format(np.mean(acc_score)))\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print()\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print()\n",
    "print(classification_report(Truth, Output))\n",
    "\n",
    "cm = confusion_matrix(Truth, Output)\n",
    "\n",
    "sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "f1_score = (2*precision*sensitivity)/(precision+sensitivity)\n",
    "\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(precision)\n",
    "print(f1_score)\n",
    "\n",
    "statcoefvar_dic['Run Time'].append(elapsed)\n",
    "statcoefvar_dic['Accuracy'].append(np.mean(acc_score))\n",
    "statcoefvar_dic['Standard Error'].append(np.std(acc_score))\n",
    "statcoefvar_dic['Sensitivity'].append(sensitivity)\n",
    "statcoefvar_dic['Specificity'].append(specificity)\n",
    "statcoefvar_dic['Precision'].append(precision)\n",
    "statcoefvar_dic['F1-Score'].append(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c0eafac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Run time is 18.30714807800001 seconds ---\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.8736712370975196, 0.8736517719568567, 0.8775038520801233, 0.8764252696456086, 0.8827426810477658]\n",
      "Avg accuracy: 0.8767989623655748\n",
      "Std of accuracy : \n",
      "0.0033362188283389293\n",
      "\n",
      "[[17065  2361]\n",
      " [ 1637 11388]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90     19426\n",
      "           1       0.83      0.87      0.85     13025\n",
      "\n",
      "    accuracy                           0.88     32451\n",
      "   macro avg       0.87      0.88      0.87     32451\n",
      "weighted avg       0.88      0.88      0.88     32451\n",
      "\n",
      "0.8784618552455472\n",
      "0.8743186180422264\n",
      "0.9124692546251738\n",
      "0.8951426772975242\n"
     ]
    }
   ],
   "source": [
    "#QDA\n",
    "kf = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "model=QuadraticDiscriminantAnalysis()\n",
    "\n",
    "acc_score = []\n",
    "Truth = []\n",
    "Output = []\n",
    "\n",
    "for train_index, test_index in kf.split(subject_df):\n",
    "    \n",
    "    X_train = subject_df.iloc[train_index, 13].values.reshape(-1,1)\n",
    "    X_test = subject_df.iloc[test_index, 13].values.reshape(-1,1)\n",
    "    Y_train = subject_df.iloc[train_index, -1]\n",
    "    Y_test = subject_df.iloc[test_index, -1]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "    \n",
    "\n",
    "    acc = accuracy_score(Y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "    Truth.extend(Y_test.values.reshape(Y_test.shape[0])) \n",
    "    Output.extend(pred_values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "print(\"---Run time is %s seconds ---\" % elapsed)\n",
    "print()\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print(\"Avg accuracy: {}\".format(np.mean(acc_score)))\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print()\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print()\n",
    "print(classification_report(Truth, Output))\n",
    "\n",
    "cm = confusion_matrix(Truth, Output)\n",
    "\n",
    "sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "f1_score = (2*precision*sensitivity)/(precision+sensitivity)\n",
    "\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(precision)\n",
    "print(f1_score)\n",
    "\n",
    "statcoefvar_dic['Run Time'].append(elapsed)\n",
    "statcoefvar_dic['Accuracy'].append(np.mean(acc_score))\n",
    "statcoefvar_dic['Standard Error'].append(np.std(acc_score))\n",
    "statcoefvar_dic['Sensitivity'].append(sensitivity)\n",
    "statcoefvar_dic['Specificity'].append(specificity)\n",
    "statcoefvar_dic['Precision'].append(precision)\n",
    "statcoefvar_dic['F1-Score'].append(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a6d0f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.82714528 0.82003082 0.82141757 0.82942989 0.83112481]\n",
      "\n",
      "Avg accuracy: 0.8258296719482873\n",
      "\n",
      "K=2\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.80126329 0.79738059 0.79691834 0.80446841 0.80215716]\n",
      "\n",
      "Avg accuracy: 0.8004375573717217\n",
      "\n",
      "K=3\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.84147281 0.84884438 0.85192604 0.84853621 0.85839753]\n",
      "\n",
      "Avg accuracy: 0.8498353937501232\n",
      "\n",
      "K=4\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.8373132  0.84483821 0.84822804 0.84453005 0.84607088]\n",
      "\n",
      "Avg accuracy: 0.8441960766347336\n",
      "\n",
      "K=5\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.8567247  0.85731895 0.86224961 0.85932203 0.86887519]\n",
      "\n",
      "Avg accuracy: 0.8608980978522116\n",
      "\n",
      "K=6\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.85425974 0.85546995 0.85901387 0.85531587 0.86594761]\n",
      "\n",
      "Avg accuracy: 0.8580014095610397\n",
      "\n",
      "K=7\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.86458173 0.86394453 0.86594761 0.8651772  0.87411402]\n",
      "\n",
      "Avg accuracy: 0.8667530175122173\n",
      "\n",
      "K=8\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.8624249  0.86502311 0.8624037  0.86224961 0.87211094]\n",
      "\n",
      "Avg accuracy: 0.8648424522374111\n",
      "\n",
      "K=9\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.86689262 0.86533128 0.86702619 0.86979969 0.87411402]\n",
      "\n",
      "Avg accuracy: 0.8686327613984423\n",
      "\n",
      "K=10\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.86704668 0.86302003 0.86209553 0.86810478 0.87473035]\n",
      "\n",
      "Avg accuracy: 0.8669994746785818\n",
      "\n",
      "K=11\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.86827916 0.86687211 0.86671803 0.86918336 0.87966102]\n",
      "\n",
      "Avg accuracy: 0.870142734078405\n",
      "\n",
      "K=12\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.86843322 0.86856703 0.87057011 0.86933744 0.87503852]\n",
      "\n",
      "Avg accuracy: 0.8703892624586989\n",
      "\n",
      "K=13\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.86997381 0.86640986 0.86810478 0.86949153 0.87750385]\n",
      "\n",
      "Avg accuracy: 0.8702967650597877\n",
      "\n",
      "K=14\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.87243876 0.86795069 0.86887519 0.86979969 0.87873652]\n",
      "\n",
      "Avg accuracy: 0.8715601713786946\n",
      "\n",
      "K=15\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.8715144  0.86733436 0.87057011 0.87211094 0.87950693]\n",
      "\n",
      "Avg accuracy: 0.872207349324975\n",
      "\n",
      "K=16\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.87136035 0.86825886 0.86933744 0.87241911 0.87950693]\n",
      "\n",
      "Avg accuracy: 0.8721765374315842\n",
      "\n",
      "K=17\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.87120629 0.86795069 0.86995378 0.87272727 0.8798151 ]\n",
      "\n",
      "Avg accuracy: 0.87233062538411\n",
      "\n",
      "K=18\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.87089817 0.86887519 0.86964561 0.87457627 0.87719569]\n",
      "\n",
      "Avg accuracy: 0.8722381849563423\n",
      "\n",
      "K=19\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.87243876 0.86933744 0.87257319 0.87534669 0.87935285]\n",
      "\n",
      "Avg accuracy: 0.8738097861706823\n",
      "\n",
      "K=20\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.87367124 0.86995378 0.87164869 0.87442219 0.8779661 ]\n",
      "\n",
      "Avg accuracy: 0.8735323984210448\n",
      "\n",
      "K=21\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.87474965 0.86979969 0.87318952 0.87488444 0.88012327]\n",
      "\n",
      "Avg accuracy: 0.8745493143404202\n",
      "\n",
      "K=22\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.87413342 0.87103236 0.87303544 0.87349769 0.87904468]\n",
      "\n",
      "Avg accuracy: 0.8741487169979816\n",
      "\n",
      "K=23\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.87490371 0.87149461 0.87349769 0.87395994 0.87996918]\n",
      "\n",
      "Avg accuracy: 0.874765026079728\n",
      "\n",
      "K=24\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.87336312 0.87087827 0.87164869 0.87503852 0.88089368]\n",
      "\n",
      "Avg accuracy: 0.8743644572228609\n",
      "\n",
      "K=25\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.87259282 0.87087827 0.87272727 0.87503852 0.8798151 ]\n",
      "\n",
      "Avg accuracy: 0.8742103977559067\n",
      "\n",
      "[0.8258296719482873, 0.8004375573717217, 0.8498353937501232, 0.8441960766347336, 0.8608980978522116, 0.8580014095610397, 0.8667530175122173, 0.8648424522374111, 0.8686327613984423, 0.8669994746785818, 0.870142734078405, 0.8703892624586989, 0.8702967650597877, 0.8715601713786946, 0.872207349324975, 0.8721765374315842, 0.87233062538411, 0.8722381849563423, 0.8738097861706823, 0.8735323984210448, 0.8745493143404202, 0.8741487169979816, 0.874765026079728, 0.8743644572228609, 0.8742103977559067]\n",
      "0.874765026079728\n"
     ]
    }
   ],
   "source": [
    "KNN_result = []\n",
    "X=subject_df.iloc[:, 13].values.reshape(-1,1)\n",
    "Y=subject_df.iloc[:, -1]\n",
    "crossvalidation = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "KNNResult = []\n",
    "for k in range(1,26):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    model = knn.fit(X, Y)\n",
    "    scores=cross_val_score(model, X, Y, cv=crossvalidation)\n",
    "    print('K={}'.format(k))\n",
    "    print()\n",
    "    print('Accuracy of each fold: \\n {}'.format(scores))\n",
    "    print()\n",
    "    print(\"Avg accuracy: {}\".format(scores.mean()))\n",
    "    print()\n",
    "    KNN_result.append(scores.mean())\n",
    "print(KNN_result)\n",
    "print(np.max(KNN_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "240dd696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Run time is 591.2412271569999 seconds ---\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.8645817285472193, 0.863944530046225, 0.8659476117103235, 0.8651771956856703, 0.8741140215716486]\n",
      "Avg accuracy: 0.8667530175122173\n",
      "Std of accuracy : \n",
      "0.00373947513199029\n",
      "\n",
      "[[16717  2709]\n",
      " [ 1615 11410]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89     19426\n",
      "           1       0.81      0.88      0.84     13025\n",
      "\n",
      "    accuracy                           0.87     32451\n",
      "   macro avg       0.86      0.87      0.86     32451\n",
      "weighted avg       0.87      0.87      0.87     32451\n",
      "\n",
      "0.8605477195511171\n",
      "0.8760076775431862\n",
      "0.9119026838315514\n",
      "0.8854812225223794\n"
     ]
    }
   ],
   "source": [
    "#KNN-CV\n",
    "kf = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "model=neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "acc_score = []\n",
    "Truth = []\n",
    "Output = []\n",
    "\n",
    "for train_index, test_index in kf.split(subject_df): \n",
    "    \n",
    "    X_train = subject_df.iloc[train_index, 13].values.reshape(-1,1)\n",
    "    X_test = subject_df.iloc[test_index, 13].values.reshape(-1,1)\n",
    "    Y_train = subject_df.iloc[train_index, -1]\n",
    "    Y_test = subject_df.iloc[test_index, -1]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(Y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "    Truth.extend(Y_test.values.reshape(Y_test.shape[0])) \n",
    "    Output.extend(pred_values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"---Run time is %s seconds ---\" % elapsed)\n",
    "print()\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print(\"Avg accuracy: {}\".format(np.mean(acc_score)))\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print()\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print()\n",
    "print(classification_report(Truth, Output))\n",
    "\n",
    "cm = confusion_matrix(Truth, Output)\n",
    "\n",
    "sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "f1_score = (2*precision*sensitivity)/(precision+sensitivity)\n",
    "\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(precision)\n",
    "print(f1_score)\n",
    "\n",
    "statcoefvar_dic['Run Time'].append(elapsed)\n",
    "statcoefvar_dic['Accuracy'].append(np.mean(acc_score))\n",
    "statcoefvar_dic['Standard Error'].append(np.std(acc_score))\n",
    "statcoefvar_dic['Sensitivity'].append(sensitivity)\n",
    "statcoefvar_dic['Specificity'].append(specificity)\n",
    "statcoefvar_dic['Precision'].append(precision)\n",
    "statcoefvar_dic['F1-Score'].append(f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb7c855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
