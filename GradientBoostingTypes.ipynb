{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e63e7578",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/SAHIL/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/SAHIL/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8bf19b234eb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_evaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCVBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCFUNCTYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/SAHIL/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/SAHIL/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import wfdb\n",
    "import copy as cp\n",
    "import scipy.signal as signal\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f536e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_list = [] # Initialize the array that will hold the list of our records\n",
    "\n",
    "records = 'mit-bih-dataframes/subject_list.csv' # Get our record list like we did in the initial extraction\n",
    "with open(records) as rfile:# Load our records into the array\n",
    "    for record in rfile:\n",
    "        record = record[0:-1] # The -1 removes the newline (\"\\n\") character from the string\n",
    "        record_list.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7941e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdic = {}\n",
    "for idx, x in enumerate(record_list):\n",
    "    dfdic[x] = pd.read_csv('mit-bih-features/'+x+ '.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed231d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df = pd.DataFrame()\n",
    "for idx, x in enumerate(record_list):\n",
    "    subject_df = pd.concat([subject_df, dfdic[x]])\n",
    "subject_df = subject_df.drop([\"Unnamed: 0.1\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c58553",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df['Mappedrhythmlabels'] = subject_df['rhythmLabel'].map({'Normal':0, 'Other':0, 'AFIB':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d79a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "statgboost_dic =  {\n",
    "    'Run Time': [],\n",
    "    'Accuracy': [],\n",
    "    'Standard Error': [],\n",
    "    'Sensitivity': [],\n",
    "    'Specificity': [],\n",
    "    'Precision': [],\n",
    "    'F1-Score': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "indaccs_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Light Gradient Boosting \n",
    "LGBresults_lr1 = []\n",
    "X=subject_df.iloc[:, 2:17]\n",
    "Y=subject_df.iloc[:, -1]\n",
    "for r in range(-3, 2):\n",
    "    model=LGBMClassifier(n_estimators=500, learning_rate=10**r, max_depth=4, random_state=3)\n",
    "    scores = cross_val_score(model, X, Y, cv=crossvalidation)\n",
    "    print('Learning rate: {}'.format(10**r))\n",
    "    print()\n",
    "    print('Accuracy of each fold: \\n {}'.format(scores))\n",
    "    print(\"Avg accuracy: {}\".format(scores.mean()))\n",
    "    print()\n",
    "    LGBresults_lr1.append(scores.mean())\n",
    "print(LGBresults_lr1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4aebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Light Gradient Boosting\n",
    "LGBresults_lr2 = []\n",
    "X=subject_df.iloc[:, 2:17]\n",
    "Y=subject_df.iloc[:, -1]\n",
    "for r in range(1, 10):\n",
    "    model=LGBMClassifier(n_estimators=500, learning_rate=0.1*r, max_depth=4, random_state=3)\n",
    "    scores = cross_val_score(model, X, Y, cv=crossvalidation)\n",
    "    print('Learning rate: {}'.format(0.1*r))\n",
    "    print()\n",
    "    print('Accuracy of each fold: \\n {}'.format(scores))\n",
    "    print(\"Avg accuracy: {}\".format(scores.mean()))\n",
    "    print()\n",
    "    LGBresults_lr2.append(scores.mean())\n",
    "print(LGBresults_lr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light Gradient Boosting\n",
    "XGBresults_md = []\n",
    "X=subject_df.iloc[:, 2:17]\n",
    "Y=subject_df.iloc[:, -1]\n",
    "for d in range(1, 26):\n",
    "    model=LGBMClassifier(n_estimators=500, learning_rate=0.1, max_depth=d, random_state=3)\n",
    "    scores = cross_val_score(model, X, Y, cv=crossvalidation)\n",
    "    print('Max depth: {}'.format(d))\n",
    "    print()\n",
    "    print('Accuracy of each fold: \\n {}'.format(scores))\n",
    "    print(\"Avg accuracy: {}\".format(scores.mean()))\n",
    "    print()\n",
    "    XGBresults_md.append(scores.mean())\n",
    "print(XGBresults_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92401d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extreme Gradient Boosting \n",
    "GBresults_lr1 = []\n",
    "X=subject_df.iloc[:, 2:17]\n",
    "Y=subject_df.iloc[:, -1]\n",
    "for r in range(-3, 2):\n",
    "    model=XGBClassifier(n_estimators=500, learning_rate=10**r, max_depth=4, random_state=3)\n",
    "    scores = cross_val_score(model, X, Y, cv=crossvalidation)\n",
    "    print('Learning rate: {}'.format(10**r))\n",
    "    print()\n",
    "    print('Accuracy of each fold: \\n {}'.format(scores))\n",
    "    print(\"Avg accuracy: {}\".format(scores.mean()))\n",
    "    print()\n",
    "    GBresults_lr1.append(scores.mean())\n",
    "print(GBresults_lr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5328a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme Gradient Boosting\n",
    "GBresults_lr2 = []\n",
    "X=subject_df.iloc[:, 2:17]\n",
    "Y=subject_df.iloc[:, -1]\n",
    "for r in range(1, 10):\n",
    "    model=XGBClassifier(n_estimators=500, learning_rate=0.1*r, max_depth=4, random_state=3)\n",
    "    scores = cross_val_score(model, X, Y, cv=crossvalidation)\n",
    "    print('Learning rate: {}'.format(0.1*r))\n",
    "    print()\n",
    "    print('Accuracy of each fold: \\n {}'.format(scores))\n",
    "    print(\"Avg accuracy: {}\".format(scores.mean()))\n",
    "    print()\n",
    "    GBresults_lr2.append(scores.mean())\n",
    "print(GBresults_lr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f7db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme Gradient Boosting\n",
    "GBresults_md = []\n",
    "X=subject_df.iloc[:, 2:17]\n",
    "Y=subject_df.iloc[:, -1]\n",
    "for d in range(1, 26):\n",
    "    model=XGBClassifier(n_estimators=500, learning_rate=0.1, max_depth=d, random_state=3)\n",
    "    scores = cross_val_score(model, X, Y, cv=crossvalidation)\n",
    "    print('Max depth: {}'.format(d))\n",
    "    print()\n",
    "    print('Accuracy of each fold: \\n {}'.format(scores))\n",
    "    print(\"Avg accuracy: {}\".format(scores.mean()))\n",
    "    print()\n",
    "    XGBresults_md.append(scores.mean())\n",
    "print(XGBresults_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Light Gradient Boosting\n",
    "kf=KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "model = LGBMClassifier(n_estimators=500, learning_rate=0.1, max_depth=8, random_state=3)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "acc_score = []\n",
    "Truth = []\n",
    "Output = []\n",
    "\n",
    "for train_index, test_index in kf.split(subject_df):\n",
    "    X_train = subject_df.iloc[train_index, 2:17]\n",
    "    X_test = subject_df.iloc[test_index, 2:17]\n",
    "    Y_train = subject_df.iloc[train_index, -1]\n",
    "    Y_test = subject_df.iloc[test_index, -1]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(Y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "    Truth.extend(Y_test.values.reshape(Y_test.shape[0])) \n",
    "    Output.extend(pred_values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "\n",
    "print(\"---Run time is %s seconds ---\" % elapsed)\n",
    "print()\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print(\"Avg accuracy: {}\".format(np.mean(acc_score)))\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print()\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print()\n",
    "print(classification_report(Truth, Output))\n",
    "\n",
    "cm = confusion_matrix(Truth, Output)\n",
    "\n",
    "sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "f1_score = (2*precision*sensitivity)/(precision+sensitivity)\n",
    "\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(precision)\n",
    "print(f1_score)\n",
    "\n",
    "statgboost_dic['Run Time'].append(elapsed)\n",
    "statgboost_dic['Accuracy'].append(np.mean(acc_score))\n",
    "statgboost_dic['Standard Error'].append(np.std(acc_score))\n",
    "statgboost_dic['Sensitivity'].append(sensitivity)\n",
    "statgboost_dic['Specificity'].append(specificity)\n",
    "statgboost_dic['Precision'].append(precision)\n",
    "statgboost_dic['F1-Score'].append(f1_score)\n",
    "\n",
    "indaccs_dic['LGBM']=acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db490d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extreme Gradient Boosting \n",
    "kf=KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "model = XGBClassifier(n_estimators=500, learning_rate=0.1, max_depth=8, random_state=3)\n",
    "\n",
    "start_time = timeit.default_timer(n_estimators=500, learning_rate=0.1, max_depth=8, random_state=3)\n",
    "\n",
    "acc_score = []\n",
    "Truth = []\n",
    "Output = []\n",
    "\n",
    "for train_index, test_index in kf.split(subject_df):\n",
    "    X_train = subject_df.iloc[train_index, 2:17]\n",
    "    X_test = subject_df.iloc[test_index, 2:17]\n",
    "    Y_train = subject_df.iloc[train_index, -1]\n",
    "    Y_test = subject_df.iloc[test_index, -1]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(Y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "    Truth.extend(Y_test.values.reshape(Y_test.shape[0])) \n",
    "    Output.extend(pred_values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "\n",
    "print(\"---Run time is %s seconds ---\" % elapsed)\n",
    "print()\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print(\"Avg accuracy: {}\".format(np.mean(acc_score)))\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print()\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print()\n",
    "print(classification_report(Truth, Output))\n",
    "\n",
    "cm = confusion_matrix(Truth, Output)\n",
    "\n",
    "sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "f1_score = (2*precision*sensitivity)/(precision+sensitivity)\n",
    "\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(precision)\n",
    "print(f1_score)\n",
    "\n",
    "statgboost_dic['Run Time'].append(elapsed)\n",
    "statgboost_dic['Accuracy'].append(np.mean(acc_score))\n",
    "statgboost_dic['Standard Error'].append(np.std(acc_score))\n",
    "statgboost_dic['Sensitivity'].append(sensitivity)\n",
    "statgboost_dic['Specificity'].append(specificity)\n",
    "statgboost_dic['Precision'].append(precision)\n",
    "statgboost_dic['F1-Score'].append(f1_score)\n",
    "\n",
    "indaccs_dic['XGBoost']=acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef67d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "gboostdf = pd.DataFrame(\n",
    "    data = np.transpose(np.array([\n",
    "                                statgboost_dic[\"Accuracy\"],\n",
    "                                statgboost_dic[\"Standard Error\"],\n",
    "                                statgboost_dic[\"Sensitivity\"],\n",
    "                                statgboost_dic[\"Specificity\"],\n",
    "                                statgboost_dic[\"Precision\"],\n",
    "                                statgboost_dic[\"F1-Score\"],\n",
    "                                statgboost_dic[\"Run Time\"] \n",
    "                            ])\n",
    "                       ),\n",
    "    \n",
    "    columns = [\"Accuracy\", \"Standard Error\", \"Sensitivity\", \"Specificity\", \"Precision\", \"F1-Score\", \"Run Time\"]\n",
    "    \n",
    ")\n",
    "\n",
    "gboostdf.set_index(pd.Index([\"LGBoost\", \"XGBoost\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
