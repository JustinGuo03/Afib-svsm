{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86c2fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import wfdb\n",
    "import copy as cp\n",
    "import scipy.signal as signal\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5555dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_list = [] # Initialize the array that will hold the list of our records\n",
    "\n",
    "records = 'mit-bih-dataframes/subject_list.csv' # Get our record list like we did in the initial extraction\n",
    "with open(records) as rfile:# Load our records into the array\n",
    "    for record in rfile:\n",
    "        record = record[0:-1] # The -1 removes the newline (\"\\n\") character from the string\n",
    "        record_list.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b8edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdic = {}\n",
    "for idx, x in enumerate(record_list):\n",
    "    dfdic[x] = pd.read_csv('mit-bih-features/'+x+ '.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2da5be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df = pd.DataFrame()\n",
    "for idx, x in enumerate(record_list):\n",
    "    subject_df = pd.concat([subject_df, dfdic[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd94952",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df['Mappedrhythmlabels'] = subject_df['rhythmLabel'].map({'Normal':0, 'Other':0, 'AFIB':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3bbb2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsetID</th>\n",
       "      <th>rhythmLabel</th>\n",
       "      <th>StoS</th>\n",
       "      <th>StoR</th>\n",
       "      <th>StoL</th>\n",
       "      <th>RtoS</th>\n",
       "      <th>RtoR</th>\n",
       "      <th>RtoL</th>\n",
       "      <th>LtoS</th>\n",
       "      <th>LtoR</th>\n",
       "      <th>LtoL</th>\n",
       "      <th>RMS</th>\n",
       "      <th>STD</th>\n",
       "      <th>CoefVar</th>\n",
       "      <th>Range</th>\n",
       "      <th>IQR</th>\n",
       "      <th>MAD</th>\n",
       "      <th>Mappedrhythmlabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04015-0.csv</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>156.276998</td>\n",
       "      <td>43.660906</td>\n",
       "      <td>0.248152</td>\n",
       "      <td>155.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04015-1.csv</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>197.783973</td>\n",
       "      <td>57.233572</td>\n",
       "      <td>0.355262</td>\n",
       "      <td>213.0</td>\n",
       "      <td>93.50</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04015-2.csv</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151.638551</td>\n",
       "      <td>43.820505</td>\n",
       "      <td>0.253179</td>\n",
       "      <td>138.0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04015-3.csv</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>157.611865</td>\n",
       "      <td>48.827831</td>\n",
       "      <td>0.318730</td>\n",
       "      <td>167.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04015-4.csv</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>226.855681</td>\n",
       "      <td>53.260256</td>\n",
       "      <td>0.289227</td>\n",
       "      <td>237.0</td>\n",
       "      <td>95.75</td>\n",
       "      <td>66.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subsetID rhythmLabel      StoS      StoR      StoL      RtoS      RtoR  \\\n",
       "0  04015-0.csv      Normal  0.200000  0.057143  0.028571  0.057143  0.228571   \n",
       "1  04015-1.csv      Normal  0.000000  0.052632  0.000000  0.052632  0.184211   \n",
       "2  04015-2.csv      Normal  0.333333  0.083333  0.055556  0.027778  0.305556   \n",
       "3  04015-3.csv      Normal  0.300000  0.175000  0.000000  0.125000  0.025000   \n",
       "4  04015-4.csv      Normal  0.090909  0.151515  0.090909  0.030303  0.060606   \n",
       "\n",
       "       RtoL      LtoS      LtoR      LtoL         RMS        STD   CoefVar  \\\n",
       "0  0.142857  0.057143  0.114286  0.114286  156.276998  43.660906  0.248152   \n",
       "1  0.236842  0.000000  0.210526  0.263158  197.783973  57.233572  0.355262   \n",
       "2  0.083333  0.111111  0.000000  0.000000  151.638551  43.820505  0.253179   \n",
       "3  0.125000  0.075000  0.050000  0.125000  157.611865  48.827831  0.318730   \n",
       "4  0.212121  0.212121  0.060606  0.090909  226.855681  53.260256  0.289227   \n",
       "\n",
       "   Range    IQR   MAD  Mappedrhythmlabels  \n",
       "0  155.0  78.00  32.5                   0  \n",
       "1  213.0  93.50  55.0                   0  \n",
       "2  138.0  72.00  56.0                   0  \n",
       "3  167.0  79.00  59.0                   0  \n",
       "4  237.0  95.75  66.5                   0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69552649",
   "metadata": {},
   "outputs": [],
   "source": [
    "stattransitions_dic = {\n",
    "    'Accuracy': [],\n",
    "    'Standard Error': [],\n",
    "    'Sensitivity': [],\n",
    "    'Specificity': [],\n",
    "    'Precision': [],\n",
    "    'F1_Score': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94aef49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Run time is 0.3301363290000001 seconds ---\n",
      "\n",
      "Accuracy of each fold: \n",
      " [0.9246649206593746, 0.9283513097072419, 0.9312788906009245, 0.9306625577812019, 0.9343605546995377]\n",
      "Avg accuracy: 0.929863646689656\n",
      "Std of accuracy : \n",
      "0.003230395375065387\n",
      "\n",
      "[[18564   862]\n",
      " [ 1414 11611]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94     19426\n",
      "           1       0.93      0.89      0.91     13025\n",
      "\n",
      "    accuracy                           0.93     32451\n",
      "   macro avg       0.93      0.92      0.93     32451\n",
      "weighted avg       0.93      0.93      0.93     32451\n",
      "\n",
      "0.9556264799752908\n",
      "0.8914395393474088\n",
      "0.9292221443587947\n",
      "0.9422393665617703\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'F1-Score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b6225e562c63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mstattransitions_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Specificity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecificity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mstattransitions_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mstattransitions_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'F1-Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'F1-Score'"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "acc_score = []\n",
    "Truth = []\n",
    "Output = []\n",
    "\n",
    "for train_index, test_index in kf.split(subject_df): \n",
    "    #X_train = subject_df.loc[train_index, [\"StoS\", \"StoR\", \"StoL\", \"RtoS\", \"RtoR\", \"RtoL\",\"LtoS\", \"LtoR\", \"LtoL\"]]\n",
    "    #X_test = subject_df.loc[test_index, [\"StoS\", \"StoR\", \"StoL\", \"RtoS\", \"RtoR\", \"RtoL\",\"LtoS\", \"LtoR\", \"LtoL\"]]\n",
    "    #Y_train = subject_df.loc[train_index, \"rhythmLabel\"]\n",
    "    #Y_test = subject_df.loc[test_index, \"rhythmLabel\"]\n",
    "    \n",
    "    X_train = subject_df.iloc[train_index, 2:11]\n",
    "    X_test = subject_df.iloc[test_index, 2:11]\n",
    "    Y_train = subject_df.iloc[train_index, -1]\n",
    "    Y_test = subject_df.iloc[test_index, -1]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(Y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "    Truth.extend(Y_test.values.reshape(Y_test.shape[0])) \n",
    "    Output.extend(pred_values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "\n",
    "print(\"---Run time is %s seconds ---\" % elapsed)\n",
    "print()\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print(\"Avg accuracy: {}\".format(np.mean(acc_score)))\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print()\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print()\n",
    "print(classification_report(Truth, Output))\n",
    "\n",
    "cm = confusion_matrix(Truth, Output)\n",
    "\n",
    "sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "f1_score = (2*precision*sensitivity)/(precision+sensitivity)\n",
    "\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(precision)\n",
    "print(f1_score)\n",
    "\n",
    "\n",
    "stattransitions_dic['Accuracy'].append(np.mean(acc_score))\n",
    "stattransitions_dic['Standard Error'].append(np.std(acc_score))\n",
    "stattransitions_dic['Sensitivity'].append(sensitivity)\n",
    "stattransitions_dic['Specificity'].append(specificity)\n",
    "stattransitions_dic['Precision'].append(precision)\n",
    "stattransitions_dic['F1_Score'].append(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "kf = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "model=LinearDiscriminantAnalysis()\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "acc_score = []\n",
    "Truth = []\n",
    "Output = []\n",
    "\n",
    "for train_index, test_index in kf.split(subject_df):\n",
    "    X_train = subject_df.iloc[train_index, 2:11]\n",
    "    X_test = subject_df.iloc[test_index, 2:11]\n",
    "    Y_train = subject_df.iloc[train_index, -1]\n",
    "    Y_test = subject_df.iloc[test_index, -1]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "    \n",
    "\n",
    "    acc = accuracy_score(Y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "    Truth.extend(Y_test.values.reshape(Y_test.shape[0])) \n",
    "    Output.extend(pred_values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "\n",
    "print(\"---Run time is %s seconds ---\" % elapsed)\n",
    "print()\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print(\"Avg accuracy: {}\".format(np.mean(acc_score)))\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print()\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print()\n",
    "print(classification_report(Truth, Output))\n",
    "\n",
    "cm = confusion_matrix(Truth, Output)\n",
    "\n",
    "sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "f1_score = (2*precision*sensitivity)/(precision+sensitivity)\n",
    "\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(precision)\n",
    "print(f1_score)\n",
    "\n",
    "\n",
    "stattransitions_dic['Accuracy'].append(np.mean(acc_score))\n",
    "stattransitions_dic['Standard Error'].append(np.std(acc_score))\n",
    "stattransitions_dic['Sensitivity'].append(sensitivity)\n",
    "stattransitions_dic['Specificity'].append(specificity)\n",
    "stattransitions_dic['Precision'].append(precision)\n",
    "stattransitions_dic['F1_Score'].append(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a856d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QDA\n",
    "kf = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "model=QuadraticDiscriminantAnalysis()\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "acc_score = []\n",
    "Truth = []\n",
    "Output = []\n",
    "\n",
    "for train_index, test_index in kf.split(subject_df):\n",
    "    X_train = subject_df.iloc[train_index, 2:11]\n",
    "    X_test = subject_df.iloc[test_index, 2:11]\n",
    "    Y_train = subject_df.iloc[train_index, -1]\n",
    "    Y_test = subject_df.iloc[test_index, -1]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "    \n",
    "\n",
    "    acc = accuracy_score(Y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "    Truth.extend(Y_test.values.reshape(Y_test.shape[0])) \n",
    "    Output.extend(pred_values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "\n",
    "print(\"---Run time is %s seconds ---\" % elapsed)\n",
    "print()\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print(\"Avg accuracy: {}\".format(np.mean(acc_score)))\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print()\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print()\n",
    "print(classification_report(Truth, Output))\n",
    "\n",
    "cm = confusion_matrix(Truth, Output)\n",
    "\n",
    "sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "f1_score = (2*precision*sensitivity)/(precision+sensitivity)\n",
    "\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(precision)\n",
    "print(f1_score)\n",
    "\n",
    "\n",
    "stattransitions_dic['Accuracy'].append(np.mean(acc_score))\n",
    "stattransitions_dic['Standard Error'].append(np.std(acc_score))\n",
    "stattransitions_dic['Sensitivity'].append(sensitivity)\n",
    "stattransitions_dic['Specificity'].append(specificity)\n",
    "stattransitions_dic['Precision'].append(precision)\n",
    "stattransitions_dic['F1_Score'].append(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bda346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN-CV\n",
    "KNN_result = []\n",
    "X=subject_df[[\"StoS\", \"StoR\", \"StoL\", \"RtoS\", \"RtoR\", \"RtoL\",\"LtoS\", \"LtoR\", \"LtoL\"]]\n",
    "Y=subject_df[\"Mappedrhythmlabels\"]\n",
    "crossvalidation = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "KNNResult = []\n",
    "for k in range(1,26):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    model = knn.fit(X, Y)\n",
    "    scores=cross_val_score(model, X, Y, cv=crossvalidation)\n",
    "    print('K = {}'.format(k))\n",
    "    print('Accuracy of each fold: \\n {}'.format(scores))\n",
    "    print(\"Avg accuracy: {}\".format(scores.mean()))\n",
    "    print()\n",
    "    KNN_result.append(scores.mean())\n",
    "print(KNN_result.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabfe338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN-CV\n",
    "kf = KFold(n_splits=5, random_state=3, shuffle=True)\n",
    "model=neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "acc_score = []\n",
    "Truth = []\n",
    "Output = []\n",
    "\n",
    "for train_index, test_index in kf.split(subject_df): \n",
    "    X_train = subject_df.iloc[train_index, 2:11]\n",
    "    X_test = subject_df.iloc[test_index, 2:11]\n",
    "    Y_train = subject_df.iloc[train_index, -1]\n",
    "    Y_test = subject_df.iloc[test_index, -1]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(Y_test, pred_values)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "    Truth.extend(Y_test.values.reshape(Y_test.shape[0])) \n",
    "    Output.extend(pred_values)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"---Run time is %s seconds ---\" % elapsed)\n",
    "print()\n",
    "print('Accuracy of each fold: \\n {}'.format(acc_score))\n",
    "print(\"Avg accuracy: {}\".format(np.mean(acc_score)))\n",
    "print('Std of accuracy : \\n{}'.format(np.std(acc_score)))\n",
    "print()\n",
    "print(confusion_matrix(Truth, Output))\n",
    "print()\n",
    "print(classification_report(Truth, Output))\n",
    "\n",
    "cm = confusion_matrix(Truth, Output)\n",
    "\n",
    "sensitivity = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "specificity = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = (cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "f1_score = (2*precision*sensitivity)/(precision+sensitivity)\n",
    "\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(precision)\n",
    "print(f1_score)\n",
    "\n",
    "\n",
    "stattransitions_dic['Accuracy'].append(np.mean(acc_score))\n",
    "stattransitions_dic['Standard Error'].append(np.std(acc_score))\n",
    "stattransitions_dic['Sensitivity'].append(sensitivity)\n",
    "stattransitions_dic['Specificity'].append(specificity)\n",
    "stattransitions_dic['Precision'].append(precision)\n",
    "stattransitions_dic['F1_Score'].append(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac6d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stattransitions_dic['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d17c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
